{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\"\"\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y1a4rU5PK3g0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1659864267793,
     "user_tz": -180,
     "elapsed": 18099,
     "user": {
      "displayName": "Mike Kertser",
      "userId": "02569277039743210697"
     }
    },
    "outputId": "f204a36d-319a-4802-f2f3-1965bb63a150",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\nfrom google.colab import drive\\ndrive.mount('/content/drive')\\n\""
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Kill the warnings:\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "2_5mA1LxHoBQ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1659864270238,
     "user_tz": -180,
     "elapsed": 275,
     "user": {
      "displayName": "Mike Kertser",
      "userId": "02569277039743210697"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "MiRChYs-HoBN",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1659864380889,
     "user_tz": -180,
     "elapsed": 19158,
     "user": {
      "displayName": "Mike Kertser",
      "userId": "02569277039743210697"
     }
    },
    "outputId": "08b2b517-10d8-4289-a9ac-104d14dc407b"
   },
   "outputs": [],
   "source": [
    "# Main Dependencies:\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "import config\n",
    "\n",
    "import nltk\n",
    "from textblob import TextBlob, Word\n",
    "\n",
    "# Statistics imports:\n",
    "from statistics import mean\n",
    "import scipy.stats\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "#!python -m spacy download en_core_web_sm\n",
    "#!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Data Load\n",
    "true_df = pd.read_csv(config.true_url)\n",
    "false_df = pd.read_csv(config.false_url)\n",
    "\n",
    "true_df['class'] = 1\n",
    "false_df['class'] = 0\n",
    "\n",
    "fake_news_df = pd.concat([true_df,false_df])"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "2cnyhBcSHoBR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1659864414497,
     "user_tz": -180,
     "elapsed": 8364,
     "user": {
      "displayName": "Mike Kertser",
      "userId": "02569277039743210697"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0                                               text  class\n0           0  The head of a conservative Republican faction ...      1\n1           1  Transgender people will be allowed for the fir...      1\n2           2  The special counsel investigation of links bet...      1\n3           3  Trump campaign adviser George Papadopoulos tol...      1\n4           4  President Donald Trump called on the U.S. Post...      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>text</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>The head of a conservative Republican faction ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Transgender people will be allowed for the fir...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>The special counsel investigation of links bet...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Trump campaign adviser George Papadopoulos tol...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>President Donald Trump called on the U.S. Post...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data is highly structured allready\n",
    "fake_news_df.head()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "_fBc8eWYHoBS",
    "outputId": "eeeef77e-1142-4999-a35f-063f9b946d48",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1659864416380,
     "user_tz": -180,
     "elapsed": 265,
     "user": {
      "displayName": "Mike Kertser",
      "userId": "02569277039743210697"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Let's take a sample of 10k texts from the entire dataset\n",
    "fake_news_df = fake_news_df.sample(10000, random_state=42).reset_index(drop=True)[['text','class']]"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "dMHIdJLzHoBV",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1659864418772,
     "user_tz": -180,
     "elapsed": 3,
     "user": {
      "displayName": "Mike Kertser",
      "userId": "02569277039743210697"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# In this file one can find a vocabulary that spans the emotions by words\n",
    "# BTW, it contains phrases combined into a single word, so we will need to correct it with bigrams and trigrams accordingly\n",
    "emData = pd.read_csv(config.emData_url, sep='\\t', lineterminator='\\n')\n",
    "wordsData = pd.read_excel(config.wordsData_url, index_col=0)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "4IcbPX4hHoBb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1659864494374,
     "user_tz": -180,
     "elapsed": 17988,
     "user": {
      "displayName": "Mike Kertser",
      "userId": "02569277039743210697"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "List of emotions:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "AvR4I_6sHoBc"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "Emotions = emData['emotion'].drop_duplicates().tolist() # Pop the list of emotions\n",
    "Emotions = [emotion.title() for emotion in Emotions] # Capitalize the first letter"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "4bpeVXGKHoBc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1659864494377,
     "user_tz": -180,
     "elapsed": 10,
     "user": {
      "displayName": "Mike Kertser",
      "userId": "02569277039743210697"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Select the English dataset, one-hot-encoded (emotions)\n",
    "wordsData = wordsData[wordsData.columns.intersection(['English Word']+[emotion for emotion in Emotions])]"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "qw9r8UXPHoBd",
    "outputId": "9cadca16-e595-453b-e63a-f8426cc2cf05",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1659864494378,
     "user_tz": -180,
     "elapsed": 9,
     "user": {
      "displayName": "Mike Kertser",
      "userId": "02569277039743210697"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\n# This shall be considered on production server\\n!python -m textblob.download_corpora\\nnltk.download('omw-1.4')\\n\""
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# This shall be considered on production server\n",
    "!python -m textblob.download_corpora\n",
    "nltk.download('omw-1.4')\n",
    "\"\"\""
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "SYprlgqtHoBf",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1659864500493,
     "user_tz": -180,
     "elapsed": 1582,
     "user": {
      "displayName": "Mike Kertser",
      "userId": "02569277039743210697"
     }
    },
    "outputId": "02a06796-736f-4ae7-9522-1198ac5d5768"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "--------------------------------------- Code Phase -------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "tkJADJK2HoBo"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Check whether there is a connection? Power-down will be considered as connection loss\n",
    "from urllib.request import urlopen\n",
    "def internet_is_on():\n",
    "    try:\n",
    "        urlopen(\"http://www.google.com/\",timeout=1)\n",
    "        return True\n",
    "    except urllib.URLError as err:\n",
    "        return False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Snippet for timer tool\n",
    "import functools\n",
    "import time\n",
    "\n",
    "def timer(func):\n",
    "    \"\"\"Print the runtime of the decorated function\"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper_timer(*args, **kwargs):\n",
    "        start_time = time.perf_counter()    # 1\n",
    "        value = func(*args, **kwargs)\n",
    "        end_time = time.perf_counter()      # 2\n",
    "        run_time = end_time - start_time    # 3\n",
    "        print(f\"Finished {func.__name__!r} in {run_time:.4f} secs\")\n",
    "        return value\n",
    "    return wrapper_timer"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "SMkgqU7zHoBo",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1659864517560,
     "user_tz": -180,
     "elapsed": 248,
     "user": {
      "displayName": "Mike Kertser",
      "userId": "02569277039743210697"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "@timer\n",
    "def feature_wordsCount(df_row, Sentence, df):\n",
    "    # count the unique words in the Sentence and calculate the ratio\n",
    "    uniqueWords = len(set(Sentence.words))\n",
    "    totalWords = len((Sentence.words))\n",
    "    df.at[df_row,'uniqe_words_ratio']=uniqueWords/totalWords"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "hlIxaiHIHoBp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1659864522382,
     "user_tz": -180,
     "elapsed": 241,
     "user": {
      "displayName": "Mike Kertser",
      "userId": "02569277039743210697"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "@timer\n",
    "def feature_nounPolarity(df_row, Sentence, df):\n",
    "    # Add feature for sum of polarity index into the dataset\n",
    "    # df_row is an index of the row in the dataframe\n",
    "    try:\n",
    "        df.at[df_row,'nounPolarity'] = mean([TextBlob(nounS).sentiment.polarity for nounS in Sentence.noun_phrases])\n",
    "    except:\n",
    "        df.at[df_row,'nounPolarity'] = 0 # No nouns found"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "2Wh7DCQBHoBp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1659864525060,
     "user_tz": -180,
     "elapsed": 278,
     "user": {
      "displayName": "Mike Kertser",
      "userId": "02569277039743210697"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "@timer\n",
    "def feature_nounSubjectivity(df_row, Sentence, df):\n",
    "    # Add feature for sum of subjectivity index into the dataset\n",
    "    # df_row is an index of the row in the dataframe\n",
    "    try:\n",
    "        df.at[df_row,'nounSubjectivity'] = mean([TextBlob(nounS).sentiment.subjectivity for nounS in Sentence.noun_phrases])\n",
    "    except:\n",
    "        df.at[df_row,'nounSubjectivity'] = 0 # No nouns found"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "PH1iaMR-HoBq",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1659864527597,
     "user_tz": -180,
     "elapsed": 429,
     "user": {
      "displayName": "Mike Kertser",
      "userId": "02569277039743210697"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "@timer\n",
    "def feature_sentenceSentiment(df_row, Sentence, df):\n",
    "    # Entire phrase sentiment analysis\n",
    "    # df_row is an index of the row in the dataframe\n",
    "    polarity, subjectivity = Sentence.sentiment\n",
    "    df.at[df_row,'sentencePolarity'] = polarity\n",
    "    df.at[df_row,'sentenceSubjectivity'] = subjectivity\n",
    "    df.at[df_row,'meanPolarity_per_sentence'] = mean([sentence.polarity for sentence in Sentence.sentences])\n",
    "    df.at[df_row,'meanSubjetivity_per_sentence'] = mean([sentence.subjectivity for sentence in Sentence.sentences])"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "cpsEyn_aHoBq",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1659864529866,
     "user_tz": -180,
     "elapsed": 251,
     "user": {
      "displayName": "Mike Kertser",
      "userId": "02569277039743210697"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "@timer\n",
    "def feature_Emotions(df_row, Sentence, df):\n",
    "    # Insert the emotional count per words into dataset\n",
    "    # df_row is an index of the row in the dataframe\n",
    "    # WordsData is the English dataset, one-hot-encoded for emotions\n",
    "\n",
    "    # Reset emotions for the selected row\n",
    "    for emotion in Emotions:\n",
    "        df.at[df_row,emotion]=0\n",
    "\n",
    "    for word in [Word(word).singularize().lemmatize() for word in Sentence.words if word in wordsData.index]:\n",
    "        try:\n",
    "            for emotion in set(wordsData.columns[(wordsData[wordsData.index == word].values == 1)[0]].tolist()):\n",
    "                df.at[df_row,emotion]+=1\n",
    "        except:\n",
    "            pass # no emotonal load for that specific word"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "rpEP0QbCHoBr",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1659864532271,
     "user_tz": -180,
     "elapsed": 261,
     "user": {
      "displayName": "Mike Kertser",
      "userId": "02569277039743210697"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "@timer\n",
    "def frequency_Analysis(df_row, Sentence, df):\n",
    "    # Emotional load converting to frequency and amplitude\n",
    "    # df_row is an index of the row in the dataframe\n",
    "\n",
    "    #Sentence = TextBlob(fake_news_full_df['text'][df_row]).correct()\n",
    "    data1 = np.array([sentence.polarity for sentence in Sentence.sentences]) # Sentence polarity\n",
    "    data2 = np.array([sentence.subjectivity for sentence in Sentence.sentences]) # Sentence subjectivity\n",
    "    sentence_timing = [len(sentence.words) for sentence in Sentence.sentences] # Sentence timing\n",
    "\n",
    "    #Frequency Analysis:\n",
    "    ps1 = np.abs(np.fft.fft(data1))**2\n",
    "    ps2 = np.abs(np.fft.fft(data2))**2\n",
    "\n",
    "    time_step = 1 / np.average(sentence_timing)\n",
    "    freqs1 = np.fft.fftfreq(data1.size, time_step)\n",
    "    freqs2 = np.fft.fftfreq(data2.size, time_step)\n",
    "\n",
    "    MaxPolarityFrequency = round(max(freqs1),2) # Feature\n",
    "    MaxSubjectivityFrequency = round(max(freqs2),2) # Feature\n",
    "\n",
    "    df.at[df_row,'MaxPolarityFrequency'] = MaxPolarityFrequency\n",
    "    df.at[df_row,'MaxSubjectivityFrequency'] = MaxSubjectivityFrequency"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Fqqi-rooHoBr",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1659864534629,
     "user_tz": -180,
     "elapsed": 248,
     "user": {
      "displayName": "Mike Kertser",
      "userId": "02569277039743210697"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "@timer\n",
    "def correlation_and_entropy(df_row,Sentence,df):\n",
    "    # Test for mutual correlation of sentences polarity and subjectivity\n",
    "    # df_row is an index of the row in the dataframe\n",
    "\n",
    "    #Sentence = TextBlob(fake_news_full_df['text'][df_row]).correct()\n",
    "    data1 = np.array([sentence.polarity for sentence in Sentence.sentences]) # Sentence polarity\n",
    "    data2 = np.array([sentence.subjectivity for sentence in Sentence.sentences]) # Sentence subjectivity\n",
    "\n",
    "    # Peason correlation between polarity and subjectivity - Feature\n",
    "    try:\n",
    "       corrP, _ = pearsonr(data1, data2)\n",
    "    except:\n",
    "        corrP = 0 # less than 2 elements for correlation\n",
    "    # Spearman correlation between polarity and subjectivity - Feature\n",
    "    try:\n",
    "        corrS, _ = spearmanr(data1, data2)\n",
    "    except:\n",
    "        corrS = 0 # less than 2 elements for correlation\n",
    "\n",
    "    # Calculate entropy of words in the sentence\n",
    "    p_data = pd.DataFrame(Sentence.words).value_counts()\n",
    "    try:\n",
    "        entropy = scipy.stats.entropy(p_data)\n",
    "    except:\n",
    "        entropy = 0 # No data for entropy calculation\n",
    "\n",
    "    df.at[df_row,'corrP'] = corrP\n",
    "    df.at[df_row,'corrS'] = corrS\n",
    "    df.at[df_row,'entropy'] = entropy"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "dS6luGBoHoBs",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1659864538052,
     "user_tz": -180,
     "elapsed": 253,
     "user": {
      "displayName": "Mike Kertser",
      "userId": "02569277039743210697"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Export to csv:\n",
    "def save_current_DF(path = 'Data/',row=0):\n",
    "    filename = path+'fakeNews_corrected_features_'+str(row)+'.csv'\n",
    "    with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
    "        fake_news_full_df.dropna().to_csv(f,index=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "id": "Vq1ZtGOjcKJJ",
    "executionInfo": {
     "status": "error",
     "timestamp": 1659463358217,
     "user_tz": -180,
     "elapsed": 6,
     "user": {
      "displayName": "Mike Kertser",
      "userId": "02569277039743210697"
     }
    },
    "outputId": "2f5ee797-afb8-43f9-cf65-d8a49ea14f6f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def construct_Features(indexRange,df,correct=True):\n",
    "    # Construct the features\n",
    "    for row in indexRange:\n",
    "        print(f'Constructing features for row #{row} out of {len(df)}:')\n",
    "        try:\n",
    "          if correct:\n",
    "            Sentence = TextBlob(df['text'][row]).correct()\n",
    "          else:\n",
    "            Sentence = TextBlob(df['text'][row])\n",
    "\n",
    "          feature_wordsCount(row,Sentence,df)\n",
    "          feature_nounPolarity(row, Sentence,df)\n",
    "          feature_nounSubjectivity(row, Sentence,df)\n",
    "          feature_sentenceSentiment(row, Sentence,df)\n",
    "          feature_Emotions(row, Sentence, df)\n",
    "          frequency_Analysis(row, Sentence, df)\n",
    "          correlation_and_entropy(row, Sentence, df)\n",
    "\n",
    "          if (row%1000) == 0:  # Test connection every 1000 features, to get less traffic\n",
    "              if internet_is_on() == False:\n",
    "                save_current_DF(path = 'Data/',row=row)\n",
    "                break\n",
    "        except Exception:\n",
    "            print(f'row #{row} contains some bugs, skipping')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing features for row #0 out of 78588:\n",
      "Finished 'feature_wordsCount' in 0.0186 secs\n",
      "Finished 'feature_nounPolarity' in 4.6171 secs\n",
      "Finished 'feature_nounSubjectivity' in 0.0193 secs\n",
      "Finished 'feature_sentenceSentiment' in 0.0417 secs\n",
      "Finished 'feature_Emotions' in 2.4130 secs\n",
      "Finished 'frequency_Analysis' in 0.0124 secs\n",
      "Finished 'correlation_and_entropy' in 0.0054 secs\n",
      "Constructing features for row #1 out of 78588:\n",
      "Finished 'feature_wordsCount' in 0.0051 secs\n",
      "Finished 'feature_nounPolarity' in 0.0204 secs\n",
      "Finished 'feature_nounSubjectivity' in 0.0091 secs\n",
      "Finished 'feature_sentenceSentiment' in 0.0143 secs\n",
      "Finished 'feature_Emotions' in 0.2050 secs\n",
      "Finished 'frequency_Analysis' in 0.0071 secs\n",
      "Finished 'correlation_and_entropy' in 0.0037 secs\n",
      "Constructing features for row #2 out of 78588:\n",
      "Finished 'feature_wordsCount' in 0.0057 secs\n",
      "Finished 'feature_nounPolarity' in 0.0215 secs\n",
      "Finished 'feature_nounSubjectivity' in 0.0119 secs\n",
      "Finished 'feature_sentenceSentiment' in 0.0157 secs\n",
      "Finished 'feature_Emotions' in 0.1499 secs\n",
      "Finished 'frequency_Analysis' in 0.0068 secs\n",
      "Finished 'correlation_and_entropy' in 0.0028 secs\n",
      "Constructing features for row #3 out of 78588:\n",
      "Finished 'feature_wordsCount' in 0.0055 secs\n",
      "Finished 'feature_nounPolarity' in 0.0230 secs\n",
      "Finished 'feature_nounSubjectivity' in 0.0160 secs\n",
      "Finished 'feature_sentenceSentiment' in 0.0151 secs\n",
      "Finished 'feature_Emotions' in 0.1410 secs\n",
      "Finished 'frequency_Analysis' in 0.0065 secs\n",
      "Finished 'correlation_and_entropy' in 0.0028 secs\n",
      "Constructing features for row #4 out of 78588:\n",
      "Finished 'feature_wordsCount' in 0.0133 secs\n",
      "Finished 'feature_nounPolarity' in 0.0586 secs\n",
      "Finished 'feature_nounSubjectivity' in 0.0211 secs\n",
      "Finished 'feature_sentenceSentiment' in 0.0317 secs\n",
      "Finished 'feature_Emotions' in 0.5054 secs\n",
      "Finished 'frequency_Analysis' in 0.0138 secs\n",
      "Finished 'correlation_and_entropy' in 0.0044 secs\n",
      "Constructing features for row #5 out of 78588:\n",
      "Finished 'feature_wordsCount' in 0.0015 secs\n",
      "Finished 'feature_nounPolarity' in 0.0061 secs\n",
      "Finished 'feature_nounSubjectivity' in 0.0033 secs\n",
      "Finished 'feature_sentenceSentiment' in 0.0040 secs\n",
      "Finished 'feature_Emotions' in 0.0539 secs\n",
      "Finished 'frequency_Analysis' in 0.0016 secs\n",
      "Finished 'correlation_and_entropy' in 0.0026 secs\n",
      "Constructing features for row #6 out of 78588:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the united dataset\n",
    "fake_news_full_df = pd.concat([true_df,false_df]).reset_index(drop=True)[['text','class']].dropna()\n",
    "construct_Features(range(len(fake_news_full_df)),fake_news_full_df,correct=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "name": "fakeNews - features.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/kertser/FakeNews/blob/master/fakeNews.ipynb",
     "timestamp": 1659436453521
    }
   ],
   "collapsed_sections": []
  },
  "accelerator": "TPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}